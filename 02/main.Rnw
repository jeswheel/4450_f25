\input{../header}

% \mode<beamer>{\usetheme{AnnArbor}}
\mode<beamer>{\usetheme{metropolis}}
\mode<beamer>{\metroset{block=fill}}
% \mode<beamer>{\usecolortheme{wolverine}}

\mode<beamer>{\setcounter{tocdepth}{2}}
\mode<beamer>{\setbeamertemplate{section in toc}[sections numbered]}
\mode<beamer>{\setbeamertemplate{subsection in toc}[subsections numbered indented]}

% \mode<beamer>{\usefonttheme{serif}}
\mode<beamer>{\setbeamertemplate{footline}}
\mode<beamer>{\setbeamertemplate{footline}[frame number]}
\mode<beamer>{\setbeamertemplate{frametitle continuation}[from second][\insertcontinuationcountroman]}
\mode<beamer>{\setbeamertemplate{navigation symbols}{}}

\mode<handout>{\pgfpagesuselayout{2 on 1}[letterpaper,border shrink=5mm]}

\newcommand\CHAPTER{2}
% \newcommand\answer[2]{\textcolor{blue}{#2}} % to show answers
% \newcommand\answer[2]{\textcolor{red}{#2}} % to show answers
 \newcommand\answer[2]{#1} % to show blank space

\title{\vspace{2mm} \link{https://jeswheel.github.io/4450_f25/}{Mathematical Statistics I}\\ \vspace{2mm}
Chapter \CHAPTER: Probability}
\author{Jesse Wheeler}
\date{}

\setbeamertemplate{footline}[frame number]

<<setup,include=FALSE,cache=FALSE,purl=FALSE,child="../setup.Rnw">>=
@

\begin{document}

\maketitle

\mode<article>{\tableofcontents}

\mode<presentation>{
  \begin{frame}{Outline}
    \tableofcontents
  \end{frame}
}

\section{Introduction}

\begin{frame}{Introduction}
  
  \begin{itemize}
  \item Formally, a \alert{random variable} is a function from a sample space $\Omega$ to the real numbers\footnote{In this class, will assume real-valued spaces, though more generally a random variable can map to any measureable space}.
  
  \item That is, for any element $\omega \in \Omega$, a random variable $X$ will map $\omega$ to a real number: $X(\omega) \in \R$.
  
  \item Most often people think of random variables as random numbers rather than functions; in most instances in this class, this treatment will be sufficient.
  \end{itemize}
\end{frame}

\begin{frame}{Example of a random variable}
  Consider the experiment of flipping three coins. The sample space is
  $$
  \Omega = \{hhh, hht, hth, thh, htt, tht, tth, ttt\}.
  $$
  
  \begin{itemize}
    \item Some possible random variables include (1) the number of heads, (2) the number of tails, (3) the number of heads minus the number of tails.
  
    \item Importantly, a random variable must assign a value to all possible outcomes $\omega \in \Omega$.
  \end{itemize}
  
  \begin{exampleblock}{Number of Heads}
    Let $X$ be the random variable representing the number of heads. If the result of the outcome is the event $hth$, the $X(\{hth\}) = 2$.
  \end{exampleblock}
  
\end{frame}

\begin{frame}{A few comments on random variables}
  \begin{itemize}
    \item Sometimes in this course I will use the abbreviation RV to mean ``random variable", and you can do so as well.
    \item It is conventional to use uppercase letters (math text or italics) to denote random variables.
    \item While a random variable is a function, the outcome of an experiment $\omega \in \Omega$ is random (that's the point), and we only ever see a single outcome.
    Thus, the fact that $X$ is a function is often dropped, and we just write $X$. 
    The realized value of $X$ is random, because the input is random. 
  \end{itemize}
\end{frame}

\section{Discrete Random Variables}

\begin{frame}{Discrete Random Variables}
  \begin{block}{Definition: Discrete random variable}
    A discrete random variable is a random variable that can take on only a finite or at most a countably infinite number of values.
  \end{block}
  
  \begin{itemize}
    \item Example: The number of heads in three coin flips can only be in the set $\{0, 1, 2, 3\}$. Alternatively, consider flipping a coin indefinitely until you achieve a heads. The possible outcomes are in the set $\{1, 2, 3, \ldots\}$, which is countably infinite.
  \end{itemize}
\end{frame}

\begin{frame}[allowframebreaks]{Probabilities}

  \begin{itemize}

    \item The probability measure on the sample space determines the probability of the values of $X$.
    
    \item In our example, if a coin is fair, then we can assign a uniform probability measure on the sample set of flipping a coin three times. 
  
    \item That is, all outcomes are equally likely, each with probability $1/8$.
    
    \item The probability that $X$ takes on it's potential values is easily computed, by counting the number of outcomes that result in the particular value of $X$:
  \end{itemize}
  
  \begin{align*}
    P(X = 0) &= \frac{1}{8} \\
    P(X = 1) &= \frac{3}{8} \\
    P(X = 2) &= \frac{3}{8} \\
    P(X = 3) &= \frac{1}{8}.
  \end{align*}
  
  \framebreak
  
  \begin{itemize}
    \item More generally, let's assume that $X$ is a discrete RV, and denote the possible values as $x_1, x_2, \ldots$.
  There exists a function $p$ such that $p(x_i) = P(X = x_i)$ that satisfies $\sum_i p(x_i) = 1$.
  This function $p$ is called the \alert{probability mass function} (pmf) of the random variable $X$. 
  
    \item We may also be interested in calculating for all values $x \in \R$, the probability $F(x) = P(X \leq x)$; the function $F$ is called the \alert{cumulative distribution function} (cdf).
  The cdf plays a number of important roles in probability and statistics that we will see later on.
  \end{itemize}
  
  \framebreak
  
  Some notes: 
  
  \begin{itemize}
    \item The cdf is non-decreasing (see Theorem 1.2), and
    $$
    \lim_{x \rightarrow -\infty} F(x) = 0 \quad \text{and} \quad \lim_{x \rightarrow \infty} F(x) = 1.
    $$
    \item The pmf and cdf are connected: the cdf ``jumps" at all values that the pdf $p(x) > 0$.
    \item Conventionally, the pmf is usually denoted with lower-case letters (e.g., $p$, $f$), whereas the cdf is usually denoted with upper-case letters (e.g., $F$). 
  \end{itemize}
  
  \mode<article>{
    See Figures 2.1 and 2.2 of \citet{rice07} for a depiction of the pmf and cdf of the 3-coin example.
  }
  
\end{frame}

\begin{frame}{Independence}

  \begin{itemize}
    \item Jumping ahead a little bit, we will define what it means for random variables to be independent (a chapter 3 topic).
  \end{itemize}
  
  \begin{block}{Definition: Independent random variables}
    Let $X$ and $Y$ be discrete random variables defined on the same probability space, taking values $x_1, x_2, \ldots$ and $y_1, y_2, \ldots$, respectively. $X$ and $Y$ are said to be independent if, for all $i, j$, 
    $$
    P(X = x_i, Y = y_i) = P(X = x_i)P(Y = y_i).
    $$
  \end{block}
  
  \begin{itemize}
    \item This definition follows very similarly to that of independent events. We can also extend this definition to \alert{mutual independence} of many variables if the probabilities of all combinations of variables can be factored.
  \end{itemize}
  
\end{frame}

\subsection{Common random variables}

\subsubsection{Bernoulli Random Variables}

\begin{frame}{Bernoulli Random Variables}

  \begin{itemize}
    \item A Bernoulli RV only takes on two values\footnote{Sometimes you'll see the random variable take values $-1$ and $1$.}, $0$ and $1$, with probabilities $1-p$ and $p$, respectively.
  The pmf is therefore
  \begin{align*}
    p(1) &= p \\
    p(0) &= 1-p \\
    p(x) &= 0, \quad \text{if } x \neq 0 \text{ and } x\neq 1.
  \end{align*}

    \item By using the output of $0$ and $1$, the pmf is usually written in a more compact form:
  $$
  p(x) = \begin{cases} 
    p^x(1 - p)^x, & \text{if } x = 0\, \text{ or } x = 1,\\
    0 & \text{otherwise}
  \end{cases}
  $$
  \end{itemize}
  
\end{frame}

\begin{frame}{Indicator functions}
  \begin{itemize}
    \item A common instance of a Bernoulli RV is an \alert{indicator random variable}.
  Let $I_A$ be the random variable that takes on the value of $1$ if the event $A \subset \Omega$ occurs, and $0$ otherwise:
  $$
  I_A(\omega) = \begin{cases}
    1 & \omega \in A \\
    0 & \text{otherwise}
  \end{cases}
  $$
  \item Here, we see that $P(I_A = 1) = P(A)$. 
  \end{itemize}
\end{frame}

\subsubsection{Binomail Distribution}

\begin{frame}[allowframebreaks]{Binomial Distribution}

  \begin{itemize}
    \item Using what we know about independent RVs and Bernoulli RVs, we can derive the pmf for a Binomial distribution.
  
    \item Suppose that we have $n$ independent experiments, where $n$ is a fixed (positive) integer.
  Let each experiment have two outcomes with probabilities $p$ and $1-p$, respectively, which we call ``success" or ``failure".
  We are interested now in the random variable $X$, the number of ``successes" in $n$ independent trials.
  
  \item \emph{Question:} What is the probability that $X = k$, for some $k \in \{0, 1, 2, \ldots\}$?
  \end{itemize}
  
  \framebreak
  
  \emph{Solution Sketch}: 
  
  \mode<article>{
  
    \begin{itemize}
      \item For $X = k$, we must have \emph{exactly} $k$ successes and $n-k$ failures. By the multiplication law, any one such sequence has probability $p^k(1 - p)^{n-k}$ (for instance suppose $n = 3$. What is the probability of the event $SFS$? it's $p \times (1-p) \times p = p^2(1-p)^{3-2}$.)
    
      \item Because we only care about the \emph{number} of successes, not the order, we now have a counting problem: with $n$ total trials (positions), how many ways can we arrange the $k$ successes? Another way of thinking is: ``How many ways can we choose $k$ out of $n$ locations in a sequence to place the successes?".
    
    \item The answer is $\binom{n}{k}$, so in total, the probability that $X = k$ is: 
    $$
    p(k) = P(X = k) = \binom{n}{k}p^k(1- p)^{n-k}.
    $$
    
    \item The function $p$ above is the pmf for the binomial distribution.
    \end{itemize}
  }
  
  \framebreak
  
  \begin{exampleblock}{Flipping Coins}
    Suppose that a coin is flipped $10$ times. What is the probability that the coin lands heads heads exactly $6$ times? 
    
    Here, $n = 10$, and success$ = $ Heads. Assuming the coin is fair, we have
    $$
    P(\text{Num Heads} = 6) = \binom{10}{6}(0.5)^6(0.5)^4 \approx 210 \times 0.00098 \approx .205
    $$
  \end{exampleblock}
  
  \framebreak
  
  \begin{itemize}
    \item Suppose a five 6-sided (fair) dice are rolled simultaneously. What is the probability that at least two of the dice show the value 6?
    
    \item Let $X$ denote the number of 6s in this experiment, which takes values in the set $\{0, 1, \ldots 5\}$.
    We want the probability that $X \geq 2$. 
    
    \item Because the different values of $X$ are mutually exclusive events (i.e., $X=2$ implies $X \neq 3$), we can calculate this as:
    $$
    P(X \geq 2) = \sum_{i \in \{2, 3, 4, 5\}} p(i) \approx \Sexpr{1 - dbinom(0, 5, 1/6) - dbinom(1, 5, 1/6)},
    $$
    where $p(i)$ is the pmf of the binomial$(5, 1/6)$ distribution. 
    
    \item Alternatively, we can use the complement set, which is smaller:
    $$
    P(X \geq 2) = 1 - P(X < 2) = 1 - \big(p(0) + p(1)\big) \approx \Sexpr{1 - dbinom(0, 5, 1/6) - dbinom(1, 5, 1/6)}
    $$
  \end{itemize}
  
 \begin{itemize} 
  \item \emph{Note:} A binomial RV can be expressed as the sum of independent Bernoulli RVs. That is, let $X_1, X_2, \ldots, X_n$ be independent Bernoulli RVs, each with $P(X_i = 1) = p$. Then,
  $Y = X_1 + X_2 + \ldots + X_n$ is a Binomial RV, with parameters $(n, p)$.
  \end{itemize}
  
\end{frame}
  
\subsubsection{Geometric and Negative Binomial Distributions}

\begin{frame}[allowframebreaks]{Geometric Distribution}
  
  \begin{itemize}
    \item We can construct a \alert{geometric} RV in a similar way that we did with the binomial distribution.
    
    \item Suppose instead of having a fixed number of trials, we continue having a trial until our first success. That means that if $X = k$, we will have $k-1$ failures, one success, and then stop.
    
    \item Thus, the pmf can easily be constructed to be: 
    $$
    p(k) = P(X = k) = (1-p)^{k-1}p, \quad k = 1, 2, 3, \ldots
    $$
  \end{itemize}
  
  \framebreak
  
  \begin{block}{Geometric Series}
    Recall from calculus the geometric series:
    $$
    \sum_{i = 0}^\infty r^i = \frac{1}{1 - r}, \quad \text{if } 0 < r < 1.
    $$
    This identity occurs in the pmf of the geometric series. Let $0 < p < 1$, then
    $$
    \sum_{k = 1}^\infty (1 - p)^{k-1}p = p\sum_{j = 0}^\infty (1-p)^j = p\frac{1}{1 - (1-p)} = 1.
    $$
  \end{block}
  
\end{frame}

\begin{frame}[allowframebreaks]{Negative Binomial Distribution}
  
  \begin{itemize}
    \item The \alert{negative binomial} (NB) distribution can be thought of as a generalization of the geometric distribution; rather than stopping when we have exactly one success, we now will stop when we have $r$ successes.
  
    \item For any particular sequence of trials of length $k$ that satisfy this condition, the probability is $p^r(1 - p)^{k - r}$.
  
    \item The last trial must be a success (because we stopped), so we need to choose the location of the remaining $r - 1$ successes. 
    
    \item Thus, if $X$ has a negative binomial distribution, the pmf is:
  $$
  p(k) = P(X = k) = \binom{k-1}{r - 1}p^r(1-p)^{k-r}.
  $$
  \end{itemize}
  
  \framebreak
  
    \begin{itemize}
      \item Another way that can be helpful for thinking about the NB-distribution is considering it as the sum of $r$ independent geometric random variables: 
  
      \item We want to represent the total number of trials until the $r$th success, which is the sum of the number of trials until (and including) the first success, plus the number of trials from the first success until (and including) the second success, and continued until we get $r$ successes.
    \end{itemize}
  
  \begin{exampleblock}{Negative Binomial Lottery}
    Suppose that there is a type of lottery where each purchased ticket has equal probability of winning $(p = 1/100)$, and there are 3 total prizes to be won. 
    What is the probability that exactly $k$ tickets will be sold until all prizes have been won? 
    $$
    P(X = k) = \binom{k-1}{3 - 1}(0.01)^3(0.99)^{k-3}.
    $$
    
  \end{exampleblock}
  
\end{frame}

\subsubsection{Hypergeometric and Poisson Distribution}

\begin{frame}[allowframebreaks]{The Hypergeometric Distribution}

  \begin{itemize}
    \item Suppose that there is a total population of size $n$, and $r$ have some trait of interest (``success"), and $n-r$ do not (``failure").
    
    \item If we sample $m$ items from the population, then the total number of ``successes" in our sample of size $m$ follows a hypergeometric distribution:
$$
P(X = k) = \frac{\binom{r}{k}\binom{n-r}{m-k}}{\binom{n}{m}}.
$$
  \end{itemize}

\framebreak

  \begin{itemize}
  
  \item Combinatorially, for $X = k$, we must select $k$ successes out of the total possible $r$ successes in the entire population; there are $\binom{r}{k}$ ways to do this.

  \item Since we selected $m$ objects in our sample, and we want $m-k$ of them to be failures, we must pick $m-k$ failures from the $n-r$ failures in the population; there are $\binom{n-r}{m-k}$ ways to do this.

  \item Together, the multiplication principle implies there are $\binom{r}{k}\binom{n-r}{m-k}$ ways that a sample of size $m$ contains $k$ successes from described population.

\mode<presentation>{
  \item Finally, there are a total of $\binom{n}{m}$ ways we can pick our sample.
}

\mode<article>{
\item Finally, there are a total of $\binom{n}{m}$ ways we can pick our sample:

$$
P(X = k) = \frac{\binom{r}{k}\binom{n-r}{m-k}}{\binom{n}{m}}.
$$
}

\end{itemize}

\begin{exampleblock}{Balls in a basket}
  Suppose that there are $n$ balls in a basket, and $r$ balls are black, $n-r$ balls are some other color. If we select $1 \leq m < n$ balls randomly (without replacement), let $X$ denote the number of black balls in our sample of size $m$. Then, for all $0 \leq k \leq r$,
  $$
  P(X = k) = \frac{\binom{r}{k}\binom{n-r}{m-k}}{\binom{n}{m}}.
  $$
\end{exampleblock}

\end{frame}

\begin{frame}[allowframebreaks]{The Poisson Distribution}

  \begin{itemize}
    \item The Poisson distribution is used very frequently in both theory and practice, though the derivation is less intuitive than other distributions, so we will first just provide the pmf:
  \end{itemize}
  
  \begin{block}{Definition: Poisson Distribution}
    The pmf of a random variable $X$ that follows a Poisson distribution with parameter $\lambda > 0$ is
    $$
    p(k) = P(X = k) = \frac{\lambda^k}{k!}e^{-\lambda}, \quad k = 0, 1, 2, \ldots
    $$
  \end{block}
  
  \framebreak
  
  \begin{itemize}
    \item Recall from calculus that $e^x = \sum_{n = 0}^\infty \frac{x^n}{n!}$. Thus, like all pmf's, the pmf of a Poisson distributed RV sums to one:
  \end{itemize}
  
  \begin{align*}
    \sum_{k = 0}^\infty p(k) &= \sum_{k = 0} \frac{\lambda^k}{k!}e^{-\lambda} \\
    &= e^{-\lambda}\sum_{k = 0} \frac{\lambda^k}{k!} \\
    &= e^{-\lambda}e^\lambda = 1.
  \end{align*}
  
  \framebreak
  
  \begin{itemize}
    \item The value of $\lambda$ controls the \emph{shape} of the distribution:
  \end{itemize}
  
  \begin{figure}[ht]
  \centering
  \includegraphics[width=0.55\textwidth]{poisson.png}
  \caption{\label{fig:poisson}Shape of the Poisson distribution for various values of $\lambda$ \citep{wiki:poisson}.}
  \end{figure}
 
\framebreak

\begin{itemize}
  \item The Poisson distribution can be derived as the limit of a binomial distribution as the number of trials $n \rightarrow \infty$, and $p\rightarrow 0$, such that $np = \lambda$.
\end{itemize}

\mode<presentation>{
  See next slide.
}

\framebreak

\emph{Derivation:} 

\mode<article>{

\vspace{2mm}

Recall the pmf of the binomal distribution can be expressed as
$$
p(k) = \frac{n!}{k!(n - k)!}p^k(1- p)^{n-k}.
$$
Setting $np = \lambda$, the expression becomes:
\begin{align*}
  p(k) &= \frac{n!}{k!(n - k)!} \Big(\frac{\lambda}{n}\Big)^k \Big(1 - \frac{\lambda}{n}\Big)^{n-k} \\
  &= \frac{\lambda^k}{k!}\frac{n!}{(n-k)!}\frac{1}{n^k}\Big(1 - \frac{\lambda}{n}\Big)^n\Big(1 - \frac{\lambda}{n}\Big)^{-k}
\end{align*}

Now taking the limit $n \rightarrow \infty$,
\begin{align*}
  \frac{\lambda}{n} &\rightarrow 0 \\
  \frac{n!}{(n-k)!n^k} &\rightarrow 1 \\
  \Big(1 - \frac{\lambda}{n}\Big)^n &\rightarrow e^{-\lambda} \\
  \Big(1 - \frac{\lambda}{n}\Big)^{-k} &\rightarrow 1
\end{align*}

And therefore
$$
p(k)\rightarrow \frac{\lambda^ke^{-\lambda}}{k!}.
$$
}

\framebreak

\mode<presentation>{
\emph{Derivation (continued):} 
}

\framebreak

This derivation suggests how a Poisson distribution can arise in practice.

\begin{itemize}
  \item Let $X$ denote the random variable representing the number of times some event occurs in a fixed time interval.
  \item Think of dividing the interval into very large number of small sub-intervals of equal length.
  \item Assume that the sub-intervals are so small that the probability of more than one event in a sub-interval is negligible relative to the probability of one event (which itself is small).
  \item Finally, assume that the probability of an event in a given sub-interval is identical and independent of that of other sub-intervals.
\end{itemize}

\framebreak

\begin{itemize}
  \item Following this, X is nearly binomially distributed, with $n$ being the number of sub-intervals, and $p = \lambda / n$ the probability of the event in each sub-interval.
  \item Taking the limit, we get something that is nearly Poisson distributed.
\end{itemize}

\framebreak

\begin{itemize}

\item This idea can actually be formalized and made rigorous; you would probably see something like this in a course on stochastic processes.

\item The Poisson distribution is often used to model the number of events that occur in a fixed interval.
\end{itemize}

\framebreak

The Poisson distribution is often good model for the number of events in a fixed time interval if the following conditions are met:
\begin{itemize}
  \item The occurrence of one event does not affect the occurrence of another.
  \item The rate at which events occur is fixed.
  \item Two events cannot occur at the exact same instant.
\end{itemize}

In this scenario, the random (stochastic) process that generates the data is called a \alert{Poisson process}, which gives rise to the name \alert{rate} for the parameter $\lambda$.

\framebreak

\begin{exampleblock}{Example: Telephone calls}
  Suppose that an office receives telephone calls as a Poisson process with $\lambda = 0.5$ calls per minute.
  The number of calls in a 5-min. interval follows a Poisson distribution with parameter $5\lambda = 2.5$. Thus, the probability of no calls in a 5-min. interval is $p(0) = e^{-2.5} \approx .082$; the probability one one call is $p(1) = 2.5 e^{-2.5} \approx .205$
\end{exampleblock}

\end{frame}

\section{Continuous Random Variables}

\begin{frame}{Introduction}

  \begin{itemize}
    \item Because discrete RVs take only a finite number of possibilities, they are relatively simple to define.
  
    \item In many situations, however, we are interested in random variables that can take on a continuum of values rather than a finite (or countably infinite) number.
  \end{itemize}
  
  \begin{exampleblock}{Example: Lifetime of electronic}
    We might be interested in the lifetime of an electronic component; the total lifetime may be random, but may take on any positive real number.
  \end{exampleblock}
  
\end{frame}

\begin{frame}{Density function}
  \begin{itemize}
    \item For continuous random variables, we no longer have a pmf (which maps all values of the random variable to their corresponding probabilities).
    \item Instead, the role of the pmf is taken by a \alert{probability density function} (pdf), which we will denote $f(x)$.
  \end{itemize}
  
  \begin{block}{Basic properties of a pdf}
    If $f(x)$ is a pdf, then $f(x) \geq 0$ for all $x$, $f$ is piece-wise continuous, and $\int_{-\infty}^{\infty} f(x) dx = 1$.
  \end{block}
  
\end{frame}

\begin{frame}{Probabilities}
  \begin{itemize}
    \item If $X$ is a random variable with a density function $f$, then for any $a \leq b$, the probability that $X$ falls in the interval $(a, b)$ (with the treatment that if $a = b$, the interval collapses to the set $\{a\}$) is given by: 
  $$
  P(a < X < b) = \int_{a}^b f(x) dx.
  $$
  \item An immediate consequence of this definition is that $P(X = a) = 0$ for any $a \in \R$.
  \end{itemize}
  
\end{frame}

\begin{frame}[allowframebreaks]{Example: Continuous uniform random variable}
  
  \begin{itemize}
    \item By \emph{uniform} probability, we mean that all outcomes in the given set are equally as likely.
    \item For example, if $X$ is a RV with uniform distribution on the interval $[0, 1]$, then any real number in this interval is equally likely, and the probability that $X$ is in a sub-interval of length $h$ should be equal to $h$. 
    \item You can verify that the following density satisfies this condition: 

$$
f(x) = \begin{cases}
1, & 0 \leq x \leq 1\\
0 & x < 0 \text{ or } x > 1.
\end{cases}
$$
\end{itemize}

\mode<article>{

\begin{itemize}
  \item For instance, we can pick some $c \in [0, 1]$, and $h \in (0, 1-c)$. Then the probability that $X \in (c, c+h)$ is given by:
\end{itemize}

$$
P(c < X < c+h) = \int_{c}^{c+h}1_{0 \leq x \leq 1}dx = \int_c^{c+h}1dx = (c + h) - c = h.
$$

}

\framebreak

\begin{itemize}
  \item The previous density can be generalized to any interval $[a, b]$, such that $a < b$.
\end{itemize}

\subsection{The Uniform Random Variable}

\begin{block}{Continuous uniform density}
  If $X$ is a RV uniformly distributed on an interval $[a, b]$, where $a < b$, then the corresponding density function is: 
  $$
  f(x) = \begin{cases}
  1 / (b - a) & a \leq x \leq b\\
  0 & x < a \text{ or } x > b.
  \end{cases}
  $$
\end{block}

\framebreak

\begin{itemize}
  \item One important thing to note is that if $X$ is a continuous RV, then
$$
P(a < X < b) = P(a \leq X < b) = P(a < X \leq b).
$$
  \item This is because the probability $X$ being any particular value is zero; if this were not the case, then the probability of the entire set would infinite (and probabilities must sum to one).
  \end{itemize}

\end{frame}

\subsection{The cumulative distribution function}

\begin{frame}[allowframebreaks]{Cumulative distribution function}

\begin{itemize}
  \item The cumulative distribution function of a continuous random variable $X$ is defined in the same way as for a discrete random variable:
  
  $$
  F(x) = P(X \leq x) = \int_{-\infty}^x f(x) dx.
  $$
  
  \item Thus, we can connect the cdf and the pdf of a continuous random variable using the fundamental theorem of calculus.
  
  \item Specifically, if $f(x)$ is continuous at $x$, then $F'(x)$, and
  $$
  P(a \leq X \leq b) = \int_{a}^{b} f(x)dx = F(b) - F(a).
  $$
\end{itemize}
  
  \framebreak
  
  \begin{itemize}
   \item This derivation gives some hints at properties of the cdf (both continuous and discrete RVs). Let $F$ be a distribution function. Then the following properties hold: 
  \begin{itemize}
    \item $F$ is right-continuous.
    \item $F$ is monotonically increasing (non-decreasing).
    \item $F: \R \rightarrow [0, 1]$ and satisfies $\lim_{x \rightarrow -\infty} F(x) = 0$, and $\lim_{x \rightarrow \infty} F(x) = 1$.
  \end{itemize}
  
  \item \emph{Note}: every probability distribution supported on the real numbers is uniquely identified by its distribution function $F$ (more to come).
  
  \end{itemize}
  
  \framebreak
  
  \begin{exampleblock}{cdf of continuous uniform density}
    From the definition, we can calculate the cdf of the continuous uniform density rather easily. Suppose that $X$ is uniformly distributed on $[0, 1]$. Then the cdf $F$ is:
    \begin{align*}
    F(X \leq x) &= \int_{-\infty}^x f(x)dx \\
    &= \int_{-\infty}^x 1[0 \leq x \leq 1]dx \\
    &= \begin{cases}
      0 & x < 0 \\
      x & 0 \leq x \leq 1 \\
      1 & x > 1.
    \end{cases}
    \end{align*}
  \end{exampleblock}
  
\end{frame}

\begin{frame}[allowframebreaks]{Percentiles}
  \begin{itemize}
    \item You're probably familiar with the term \alert{median}.
  For any given sample, the median defines the ``mid-point", meaning that half of the values are larger, half are smaller.
  
  \item This same concept applies to distribution functions.
  
  \item That is, the median of a distribution $F$ is defined to be that value $x_{.5}$ such that $P(X < x_{.5}) = 0.5$.
  
  \item Formally, the sample median is the same as the definition above, using the \emph{empirical} distribution function \citep{wiki:edf}.
  \end{itemize}
  
  It is important to note that, as defined, the median value may not be unique!

  \framebreak
  
  \begin{block}{Definition: Percentile}
    Let $F$ be the cdf of a continuous random variable. The $p$th quantile of the distribution $F$ is defined to be any value $x_p$ such that $F(x_p) = P(X \leq x_p) = p$. If $F$ is strictly increasing, then $x_p$ is unique and we say that $F^{-1}(p) = x_p$.
    
    If $F$ is not strictly increasing, then $x_p$ may not be unique; in this case, all such values are considered percentiles.
    If an inverse function is needed in this case, we will define $F^{-1}(p) = \inf \{x \in \R: F(x) \geq p\}$.
  \end{block}
  
  \begin{itemize}
    \item The last bit of the definition is just some important book keeping to ensure the inverse function exists in odd examples, though I don't think it comes up in this course.
  \end{itemize}
  
  \framebreak
  
  Some important percentiles have their own names, including: 
  \begin{itemize}
    \item Median: $p = 1/2$.
    \item Quartiles (lower and upper): $p = 1/4$, and $p = 3/4$, resp.
    \item Min: $p = 0$.
    \item Max: $p = 1$.
  \end{itemize}
  
  Note that the inverse cdf is sometimes called the \alert{quantile function}.
  
  \framebreak
  
  \begin{exampleblock}{Calculating the inverse cdf}
    Suppose that 
    $$
    F(x) = \begin{cases} 0 & x < 0 \\ x^2 & 0 < x < 1 \\ 1 & x > 1 \end{cases}
    $$ 
    for $0 \leq x \leq 1$. Find the inverse distribution function $F^{-1}$.
  \end{exampleblock}
  
  \emph{Solution:}
  
  \mode<article>{
  \vspace{2mm}
  First, let's check that this is a valid distribution function. First, $\lim_{x \rightarrow -\infty}F(x) = 0$, and $\lim_{x \rightarrow \infty} F(x) = 1$.
 
  \vspace{2mm}
  Now we note that it is trivially monotonically increasing from $(-\infty, 0)$ and $[1, \infty)$. Now on $[0, 1)$, $x^2$ is also increasing, and hence we have $F(x)$ is a monotonically increasing function. 
  
  \vspace{2mm}
  Finally, we need to check that it is right-continuous. In this case it is trivial, because the only points of potential discontinuity are $x = 0$ and $x = 1$, but the limit clearly exists and equals the function value at both of these points. 
  
  \vspace{2mm}
  Now to find the inverse function, we will focus on the more interesting part of the function, and solve $y = F(x) = x^2$ for $x$, obtaining $x = F^{-1}(y) = \sqrt{y}$. This provides the inverse function for all points in $(0, 1)$, but what about the endpoints? These are not unique, so we take:
  $$
  F^{-1}(0) = \inf \{x \in \R: F(x) \geq 0\} = \inf_x [0, \infty) = 0,
  $$
  and 
  $$
  F^{-1}(1) = \inf \{x \in \R: F(x) \geq 1\} = \inf_x [1, \infty) = 1.
  $$
  Fortunately, these points already match what we found in the mid-point with the square-root function: $\sqrt{0}=0$ and $\sqrt{1}=1$ (you could have guessed this would happen since the function is always continuous), so we get
  $$
  F^{-1}(p) = \sqrt{p}.
  $$
  Thus, the inverse function defined on the interval $[0, 1]$ is
  }
  
  
\end{frame}

\subsection{Common random variables}
\subsubsection{The Exponential Distribution}

\begin{frame}[allowframebreaks]{Exponential Distribution}
  \begin{itemize}
    \item The exponential density function is:
  $$
  f(x) = \begin{cases}
    \lambda e^{-\lambda x} & x \geq 0 \\
    0 & x < 0
  \end{cases}
  $$
  \item Like the Poisson distribution, the exponential density function depends on a single parameter $\lambda$.
  
  \item When this is the case, we refer to it as the \alert{family} of exponential densities that is \emph{indexed} by the parameter $\lambda$.
  \end{itemize}
  
  \framebreak
  
  \begin{itemize}
    \item The cdf is easily found via the fundamental theorem of calculus: 
  $$
  F(x) = \int_{-\infty}^x f(u)du = \begin{cases}
    1 - e^{-\lambda x} & x \geq 0 \\
    0 & x < 0
  \end{cases}
  $$
    \item From this, we can easily find quantiles of the distribution, such as the median: by solving $F(x_{(.5)}) = 1/2$
  $$
  1 - e^{-\lambda x_{(.5)}} = \frac{1}{2} \quad \implies \quad x_{(.5)} = \frac{\log 2}{\lambda}.
  $$
  \end{itemize}
  
  \framebreak
  
  \begin{itemize}
    \item The exponential distribution is often used to model lifetimes or waiting times (time-to-event).
    \item In this context, it's conventional to replace the variable $x$ with $t$. 
  
    \item The exponential distribution has a unique property known as the \alert{memoryless} property.
  
    \item That is, if something follows an exponential distribution and has already lasted a time of $s$, then the probability that it will last another $t$ units of time does not depend on $s$:
  \end{itemize}
  
  \framebreak
  
  \emph{Memoryless property:} Let $T$ be an exponentially distributed RV, and $s, t > 0$. Calculate $P(T > t + s | T > s)$.
  
  \mode<article>{
    \begin{align*}
      P(T > t+s | T > s) &= \frac{P(T > t + s \text{ and } T > s)}{P(T > s)} \\
      &= \frac{P(T > t+s)}{P(T > s)} \\
      &= \frac{1 - F(t+s)}{1 - F(s)} \\
      &= \frac{e^{-\lambda(t + s)}}{e^{-\lambda s}} \\
      &= e^{-\lambda t} = P(T > t).
    \end{align*}
  }
  
  
  \framebreak
  
  \begin{itemize}
    \item It can be shown that any continuous RV with the \emph{memoryless} property must be exponentially distributed.
  
    \item Similarly, it can be shown that any discrete RV with the \emph{memoryless} property must be geometrically distributed (maybe a HW question?)
  \end{itemize}
  
  \framebreak
  
  \begin{itemize}
    \item The exponential distribution is also related to the \emph{Poisson process} that we have discussed.
    \item Consider a poisson process with rate $\lambda$ over an interval $\mathcal{T} \subset \R$.
  
    \item While the number of events in any interval $T_0 \subset \mathcal{T}$ of length $t$ follows a Poisson distribution, the time-to-next-event $T$ follows an exponential distribution:
  
  \mode<article>{
  \item Suppose that an event occurs at time $t_0 \in T_0$, and let $T$ denote the time until next event. Then:
  \begin{align*}
  P(T > t) &= P\big(\text{no events in} (t_0, t_0 + t)\big) \\
  &= P(X = 0), \quad \text{where } X \sim \text{Pois}(\lambda t). \\
  &= e^{-\lambda t},
  \end{align*}
  \item Therefore $T$ is exponentially distributed with parameter $\lambda$.
  }
  \end{itemize}
  
\end{frame}

\subsubsection{The Gamma Density}

\begin{frame}[allowframebreaks]{The Gamma Density}
  \begin{itemize}
    \item The \alert{gamma} density function depends on two parameters $\alpha > 0$ and $\lambda > 0$.
    $$
    g(t) = \frac{\lambda^\alpha}{\Gamma(\alpha)}t^{\alpha - 1}e^{-\lambda t}, \quad t \geq 0.
    $$
    \item For $t < 0$, we define $g(t) = 0$.
    \item The \alert{gamma function}, is defined as:
    $$
    \Gamma(x) = \int_{0}^\infty u^{x - 1}e^{-u}du, \quad x > 0.
    $$
  \end{itemize}
  
  \framebreak 
  
  \begin{itemize}
    \item Note that if $\alpha = 1$, then the gamma density coincides with the exponential density. 
    \item The parameter $\alpha > 0$ in this formulation is called the \alert{shape} parameter.
    \item The parameter $\lambda > 0$ is called the \alert{scale} parameter.
    \item As the names suggest, $\alpha$ changes the \emph{shape} of the density function, whereas $\lambda$ changes the scale of the density (i.e., can be used to change from inches to feet).
  \end{itemize}
  
  % \end{frame}

  \framebreak

  % \begin{frame}{Gamma Density Figure}
  
  \begin{figure}[ht]
<<fig:gamma, fig.align='center', fig.height=4, warning=FALSE, message=FALSE, echo=FALSE>>=
library(tidyverse)
library(latex2exp)

# Parameters
alphas <- c(0.5, 1, 2, 5, 7)   # Choose several alpha (shape) values
lambda <- 1                     # Fixed scale parameter

# Define an x range that covers most of the density
x <- seq(1e-10, 12, length.out = 1000)

data.frame(
  x = x, 
  alpha_05 = dgamma(x, shape = alphas[1], scale = lambda),
  alpha_1  = dgamma(x, shape = alphas[2], scale = lambda),
  alpha_2  = dgamma(x, shape = alphas[3], scale = lambda),
  alpha_5  = dgamma(x, shape = alphas[4], scale = lambda),
  alpha_7  = dgamma(x, shape = alphas[5], scale = lambda)
) %>% 
  pivot_longer(
    cols = -x,
    names_to = "alpha",
    values_to = "value",
    names_prefix = "alpha_"
  ) %>% 
  mutate(
    alpha = case_when(
      alpha == "05" ~ "0.5", 
      TRUE ~ alpha
    )
  ) %>% 
  ggplot(aes(x = x, y = value, col = alpha, group = alpha)) + 
  geom_line() + 
  scale_y_continuous(limits = c(0, 1.25)) + 
  theme_bw() + 
  theme(legend.title = element_blank(), 
        legend.position = 'inside', 
        legend.position.inside = c(0.9,0.75),
        plot.title = element_text(hjust = 1),
        axis.title = element_blank()) + 
  scale_color_manual(
    values = c(
      '0.5' = "#c7e9b4",
      '1' = "#7fcdbb",
      '2' = "#41b6c4",
      '5' = "#2c7fb8",
      '7' = "#253494" 
    ),
    labels = c(
      '0.5' = TeX("$\\alpha = 0.5$"),
      '1' = TeX("$\\alpha = 1$"),
      '2' = TeX("$\\alpha = 2$"),
      '5' = TeX("$\\alpha = 5$"),
      '7' = TeX("$\\alpha = 7$")
    )
  ) + 
  ggtitle(TeX("$\\lambda = 1$ for all curves"))
@
  \caption{\label{fig:gamma}A few Gamma pdf functions for various levels of $\alpha$.}
  \end{figure}
  
  \end{frame}
  
\subsubsection{The Normal Distribution}
  
  \begin{frame}[allowframebreaks]{The Normal Density}
  
    \begin{itemize}
      \item The normal distribution plays a central role in both probability and statistics.
      \item It is also called \alert{the Gaussian} distribution, after Carl Friedrich Gauss, who used it as a model for modeling measurement errors. 
      \item One reason it is so important is the \alert{Central Limit Theorem} (CLT, Chapter 6), which suggests that the normal distribution is useful in a large number of settings.
      \item Roughly speaking, the CLT states that large(ish) sums (or averages) of independent random variables will be approximately normally distributed.
    \end{itemize}
  
  \framebreak 
  
  The density function for the normal distribution depends on two parameters:
  \begin{itemize}
    \item $\mu$: the mean of the distribution.
    \item $\sigma$: the standard deviation of the distribution. 
  \end{itemize}
  
  \begin{block}{The Normal Density}
    Let $X$ be a random variable that is normally distributed with mean $\mu$ and standard deviation $\sigma$. The corresponding probability density function is
    $$
    f(x) = \frac{1}{\sigma\sqrt{2\pi}}e^{-(x - \mu)^2/2\sigma^2}, \quad -\infty < x < \infty
    $$
  \end{block}
  
  \framebreak
  
  A few notes about this density / distribution:
  
  \begin{itemize}
    \item You'll often see the shorthand $X \sim N(\mu, \sigma^2)$ to mean ``X follows a normal distribution with parameters $\mu$ and $\sigma$". 
    \item The density is symmetric about $\mu$, meaning $f(\mu - x) = f(\mu + x)$; $x = \mu$ is also the maximum value of the density (mode). The ``spread" of the distribution is determined by $\sigma$. 
    \item When the mean $\mu = 0$ and standard deviation $\sigma = 1$, we call this the \alert{standard normal distribution}.
    \item There is no closed form expression for the cdf of the normal distribution. The cdf of the standard normal is usually denoted $\Phi(\cdot)$, and the pdf $\phi(\cdot)$.
  \end{itemize}
  
  \end{frame}

\subsubsection{The Beta Distribution}

\begin{frame}[allowframebreaks]{The Beta Desnity}
  \begin{itemize}
    \item The \alert{beta} distribution is useful for modeling random variables that are restricted to the interval $[0, 1]$:
    \item The density function depends on two parameters, $\alpha, \beta > 0$.
    $$
    f(x) = \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)}x^{\alpha - 1}(1 - x)^{\beta - 1}, \quad 0 \leq x \leq 1.
    $$
    \item Note that if $\alpha = \beta = 1$, the distribution becomes uniformly distributed.
    \item Both $\alpha$ and $\beta$ are shape parameters, and the distribution is quite flexible. 
  \end{itemize}
  
  \framebreak
  
    \begin{figure}[ht]
<<fig:beta, fig.align='center', fig.height=4, warning=FALSE, message=FALSE, echo=FALSE>>=
library(tidyverse)
library(latex2exp)

pars <- matrix(
  c(
    2, 6, 6, .5,  4, # alpha
    2, 2, 6,  4, .5  # beta
  ), ncol = 2
)

# Define an x range that covers most of the density
x <- seq(1e-12, 1-1e-12, length.out = 1000)

data.frame(
  x = x, 
  beta1 = dbeta(x, shape1 = pars[1, 1], shape2 = pars[1, 2]),
  beta2 = dbeta(x, shape1 = pars[2, 1], shape2 = pars[2, 2]),
  beta3 = dbeta(x, shape1 = pars[3, 1], shape2 = pars[3, 2]),
  beta4 = dbeta(x, shape1 = pars[4, 1], shape2 = pars[4, 2]),
  beta5 = dbeta(x, shape1 = pars[5, 1], shape2 = pars[5, 2])
) %>% 
  pivot_longer(
    cols = -x,
    names_to = "beta",
    values_to = "value",
    names_prefix = "beta"
  ) %>% 
  # mutate(
  #   alpha = case_when(
  #     alpha == "05" ~ "0.5", 
  #     TRUE ~ alpha
  #   )
  # ) %>% 
  ggplot(aes(x = x, y = value, col = beta, group = beta)) + 
  geom_line() + 
  scale_y_continuous(limits = c(0, 5)) +
  theme_bw() + 
  theme(legend.title = element_blank(), 
        # legend.position = 'bottom',
        # legend.position.inside = c(0.9,0.75),
        plot.title = element_text(hjust = 1),
        axis.title = element_blank()) + 
  scale_color_discrete(
    # values = c(
    #   '0.5' = "#c7e9b4",
    #   '1' = "#7fcdbb",
    #   '2' = "#41b6c4",
    #   '5' = "#2c7fb8",
    #   '7' = "#253494"
    # ),
    labels = c(
      '1' = TeX("$\\alpha = 2, \\beta = 2$"),
      '2' = TeX("$\\alpha = 6, \\beta = 2$"),
      '3' = TeX("$\\alpha = 6, \\beta = 6$"),
      '4' = TeX("$\\alpha = 0.5, \\beta = 4$"),
      '5' = TeX("$\\alpha = 4, \\beta = 0.5$")
    )
  )
@
  \caption{\label{fig:beta}A few Beta pdf functions for various levels of $\alpha$ and $\beta$.}
  \end{figure}
  
\end{frame}

\begin{frame}{Comments on density functions}
  \begin{itemize}
    \item So far, we have been using $f$ and $F$ to denote the pdf and cdf of a random variable, respectively. If there is more than one random variable, say $X$ and $Y$, we may want to distinguish between the functions, and we do so like: $f_X(x)$, or $F_Y(y)$. 
    \item There exist alternative \alert{parameterizations} of the common pmf / pdf functions we have discussed. For example, we introduced the negative binomial distribution with parameters $p$ and $r$. This is known as the size-probability parameterization, but there also exists and alternative with parameters $\mu$ and $k$, known as the mean-ddispersion parameterization (commonly used in Ecology). 
  \end{itemize}
\end{frame}

\section{Functions of a random variable}

\begin{frame}[allowframebreaks]{Variable transformations}
  \begin{itemize}
    \item Often we will be interested in function of a random variable.
    \item Let $X$ be a random variable, and $g$ an arbitrary function.
    \item Our goal is to find the distribution of the random variable $Y = g(X)$.
  \end{itemize}
  
  \begin{exampleblock}{Kinetic energy}
    Let $X$ denote a random variable representing the velocity of a particle of mass $m$; we might be interested in the distribution of $Y = \frac{1}{2}mX^2$, the particle's kinetic energy.
  \end{exampleblock}
  
  \framebreak
  
  \begin{itemize}
    \item We will eventually provide a rule for a general transformation, $g: \R \rightarrow \R$, but we will first build some intuition using simple transformations.
  \end{itemize}
  
  \begin{exampleblock}{Example: Linear Transformations (Part I)}
    Let $X$ be a random variable with pdf and cdf $f_X$ and $F_X$, respectively.
    Find the density of $Y = aX + b$, where $a > 0$, and $b \in \R$.
  \end{exampleblock}
  
  \mode<article>{
  We will use what I like to call ``the cdf method". It's a simple idea that uses the connection between the cdf and pdf of a random variable, and the definition of the cdf. 
  \begin{align*}
    F_Y(y) &= P(Y \leq y) \\
    &= P(aX + b \leq y) \\
    &= P\big(X \leq \frac{y - b}{a}\big) \\ 
    &= F_X\big(\frac{y-b}{a}\big).
  \end{align*}
  On the left, we have the cdf of $Y$, and we have equated this to the cdf of $X$. Now we can differentiate the equation with respect to $y$:
  \begin{align*}
    f_Y(y) &= \frac{d}{dy}F_X\big(\frac{y - b}{a}\big) \\
    &= \frac{1}{a} f_X\big(\frac{y-b}{a}\big).
  \end{align*}
  }
  
  \framebreak
  
  \begin{itemize}
    \item This same idea is how we will build a general formula for finding the pdf of a transformed random variable.
    \item Now let's change it slightly, and see some potential pitfalls.
  \end{itemize}
  
  \begin{exampleblock}{Example: Linear Transformations (Part II)}
    Let $X$ be a random variable with pdf and cdf $f_X$ and $F_X$, respectively.
    Find the density of $Y = aX + b$, where $a < 0$, and $b \in \R$.
  \end{exampleblock}
  
  \mode<article>{
  \begin{align*}
    F_Y(y) &= P(Y \leq y) \\
    &= P(aX + b \leq y) \\
    &= P\big(X \geq \frac{y - b}{a}\big) \\ 
    &= 1 - F_X\big(\frac{y-b}{a}\big).
  \end{align*}
  On the left, we have the cdf of $Y$, and we have equated this to the cdf of $X$. Now we can differentiate the equation with respect to $y$:
  \begin{align*}
    f_Y(y) &= 0 - \frac{d}{dy}F_X\big(\frac{y - b}{a}\big) \\
    &= -\frac{1}{a} f_X\big(\frac{y-b}{a}\big).
  \end{align*}
  \begin{itemize}
    \item Note that all pdf functions have to be positive. In this example, we have $a < 0$, and therefore the negative sign in the final result helps us ensure that $f_Y(y)$ is positive.
    \item We can also see that $\big|\frac{1}{a}\big| = -\frac{1}{a}$, so we can write:
    $$
    f_Y(y) = f_{X}\Big(\frac{y - b}{a}\Big)\Big|\frac{1}{a}\Big|.
    $$
  \end{itemize}
  }
 
 \framebreak
  
  \begin{itemize}
    \item Now, more generally, assume that $g$ is a strictly monotonically increasing function. Then: $P\big(g(X) \leq y\big) = P\big(X \leq g^{-1}(y)\big)$.
    \item If $g$ is a strictly monotonically decreasing function, then $P\big(g(X) \leq y\big) = P\big(X \geq g^{-1}(y)\big).$
    \item These two examples can be combined to give us a new proposition
  \end{itemize}
  
  \framebreak
  
  \begin{block}{Proposition 2.1: monotonic transformations}
    Let $X$ be a continuous random variable with density $f_X$, and let $Y = g(X)$, where $g$ is differentiable, and strictly monotonic on an interval $I$. Then $Y$ has the density function
    $$
    f_Y(y) = f_X\big(g^{-1}(y)\big)\Big|\frac{d}{dy}g^{-1}(y)\Big|.
    $$
    for $y$ such that $y = g(x)$, and $f_Y(y) = 0$ if $y \neq g(x)$ for any $x \in I$.
  \end{block}
  
  \emph{proof}
  
  \mode<article>{
  
  \vspace{2mm}
  Suppose that $g$ is increasing. Then 
  \begin{align*}
   F_Y(y) &= P(Y \leq y) \\
    &= P\big(g(X) \leq y\big) \\
    &= P\big(X \leq g^{-1}(y)\big) \\ 
    &= F_X\big(g^{-1}(y)\big).
  \end{align*}
  Taking the derivative, 
  $$
  f_Y(y) = f_X\big(g^{-1}(y)\big)\frac{d}{dy}g^{-1}(y) = f_X\big(g^{-1}(y)\big)\Big|\frac{d}{dy}g^{-1}(y)\Big|,
  $$
  where the last equality is a result of the fact that if $g$ is increasing, the derivative is always positive, and hence equal to it's absolute value. 
  
  \vspace{2mm}
  
  Now suppose that $g$ is decreasing. Then
    \begin{align*}
   F_Y(y) &= P(Y \leq y) \\
    &= P\big(g(X) \leq y\big) \\
    &= P\big(X \geq g^{-1}(y)\big) \\ 
    &= 1 - F_X\big(g^{-1}(y)\big).
  \end{align*}
  Taking the derivative, 
  $$
  f_Y(y) = -f_X\big(g^{-1}(y)\big)\frac{d}{dy}g^{-1}(y) = f_X\big(g^{-1}(y)\big)\Big|\frac{d}{dy}g^{-1}(y)\Big|,
  $$
  where the last equality is a result of the fact that if $g$ is decreasing, the derivative is always negative, and hence equal to it's absolute value when multiplied by negative one. 
  }
  
  \framebreak
  
  \begin{itemize}
    \item Proposition 2.1 is useful to have / know, but it's often easier to just work from scratch (we'll see a few examples of this).
    \item Proposition 2.1 can also be extended for use with non-monotonic functions $g$. The idea is that you break $g: \mathcal{X} \rightarrow \mathcal{Y}$ into a series of functions $g_i: \mathcal{X}_i \rightarrow \mathcal{Y}$ where $\mathcal{X}_i \subset \mathcal{X}$ is a set such that $g_i$ is monotonic. Then, the final density $f_Y$ can be found by summing these functions:
    $$
    f_Y(y) = \sum_{i} f_X\big(g^{-1}_i(y)\big)\Big|\frac{d}{dy}g_i^{-1}(y)\Big|.
    $$
    See \citet[][Theorem~2.1.8]{casella24} for more details.
  \end{itemize}
  
  \framebreak
  
  \begin{itemize}
    \item Here are some common RV transformations that really come in handy.
  \end{itemize}
  
  \begin{exampleblock}{Example: Normal Distribution I}
    Let $X \sim N(\mu, \sigma^2)$. Then if $Y = aX + b$, $Y\sim N(a \mu + b, a^2\sigma^2)$.
    
    \emph{proof}: direct consequence of Linear Transformation examples (parts I and II)
  \end{exampleblock}
  
  \begin{block}{Proposition 2.2: Uniform CDF}
    Let $X$ be a random variable with cdf $F$. Then $Z = F(X)$ has a uniform distribution on $[0, 1]$. 
    
    \emph{proof:} $P(Z \leq z) = P\big(F(X) \leq x\big) = P\big(X \leq F^{-1}(z)\big) = F\big(F^{-1}(z)\big) = z$
  \end{block}
  
    \framebreak
  
    \begin{block}{Proposition 2.3: Inverse Uniform CDF}
    Let $U$ be uniform on $[0, 1]$, and let $X = F^{-1}(U)$. Then the cdf of $X$ is $F$.
    
    \emph{proof:} $P(X \leq x) = P\big(F^{-1}(U) \leq x\big) = P\big(U \leq F(x)\big) = F(x)$
  \end{block}
  
  \begin{itemize}
    \item This last proposition is very useful. We can use it to \alert{generate random numbers} (pseudorandom).
    \item Many computer packages have ways of generating numbers uniformly on $U[0, 1]$; the proposition implies that to generate from any arbitrary distribution with cdf $F$, all we need to do is apply $F_{-1}$ to uniform $[0, 1]$ random numbers. 
  \end{itemize}
  
\end{frame}

\begin{frame}[allowframebreaks]{Chi-square distribution}
  \begin{itemize}
    \item If $Z \sim N(0, 1)$, find the density of $X = Z^2$.
  \end{itemize}
  
  \mode<article>{
  \begin{align*}
    F_X(x) &= P(X \leq x) \\
    &= P(-\sqrt{x} \leq Z \leq \sqrt{x})\\
    &= \Phi(\sqrt{x}) - \Phi(\sqrt{x}).
  \end{align*}
  \begin{itemize}
    \item We now find the density by differentiation the cdf with respect to $x$.
  \end{itemize}
  \begin{align*}
    f_X(x) &= \frac{1}{2}x^{-1/2}\phi(\sqrt{x}) + \frac{1}{2}x^{-1/2}\phi(-\sqrt{x}) \\
    &= x^{-1/2}\phi(\sqrt{x}) \quad \text{since } \phi \text{ is symmetric} \\
    &= \frac{x^{-1/2}}{\sqrt{2\pi}}e^{-x/2}, \quad x \geq 0. 
  \end{align*}
  \begin{itemize}
    \item If you recall that $\Gamma(1/2) = \sqrt{\pi}$, you may recognize that this is a particular instance of the gamma density, with $\alpha = \lambda = 1/2$.
    \item We call this density the \alert{chi-square density} with 1 degree of freedom.
  \end{itemize}
  }

\end{frame}

\begin{frame}{Final remarks}
  \begin{itemize}
    \item We have introduce some concepts of random variables, but a full rigorous discussion about random variables requires background in measure theory. If you are interested in learning more, a good textbook for a statistics student is \citet{resnick19}; this is considered a graduate level text, and some background in analysis will be beneficial.
    \item We have discussed only discrete and continuous random variables. In practice, we often run into random variables that have both a discrete and continuous component. For instance, consider a zero-inflated continuous random variable $X$, where $X = 0$ with probability $p$ (discrete component), but $X \sim N(0, 1)$ with probability $1-p$ (continuous component). 
  \end{itemize}
\end{frame}

\newcommand\acknowledgments{
\begin{itemize}
\item   Compiled on {\today} using \Rlanguage version \Sexpr{getRversion()}.
\item   \parbox[t]{0.75\textwidth}{Licensed under the \link{http://creativecommons.org/licenses/by-nc/4.0/}{Creative Commons Attribution-NonCommercial license}.
    Please share and remix non-commercially, mentioning its origin.}
    \parbox[c]{1.5cm}{\includegraphics[height=12pt]{../cc-by-nc}}
\item We acknowledge \link{https://jeswheel.github.io/4450_f25/acknowledge.html}{students and instructors for previous versions of this course / slides}.
\end{itemize}
}

\mode<presentation>{
\begin{frame}[allowframebreaks=0.9]{References and Acknowledgements}

\acknowledgments

\framebreak

\bibliography{../bib4450}

\end{frame}
}

\mode<article>{

\newpage

{\bf \Large \noindent Acknowledgments}

\acknowledgments

\newpage

\bibliography{../bib4450}

}



\end{document}







