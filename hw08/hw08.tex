\documentclass[10pt,twoside]{article}\usepackage[]{graphicx}\usepackage[dvipsnames,svgnames,table]{xcolor}
% maxwidth is the original width if it is less than linewidth
% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlsng}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hldef}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\usepackage[marginparsep=1em]{geometry}
\geometry{lmargin=1.0in,rmargin=1.0in, bmargin=1.2in,  tmargin=1.2in}
\usepackage[dvipsnames,svgnames,table]{xcolor}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{epstopdf}
\usepackage{verbatim}
\usepackage{enumerate}
\usepackage{bm}
\usepackage{amsthm}
\usepackage{float}
\usepackage{amsmath}
\usepackage{fancyhdr}
\usepackage{hyperref}
\usepackage{mathtools}
            
%%%%  SHORTCUT COMMANDS  %%%%
\newcommand{\ds}{\displaystyle}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\T}{\mathcal{T}}
\newcommand{\arc}{\rightarrow}
\newcommand{\R}{\mathbb{R}}
\newcommand{\RP}{\mathbb{R}(+)}
\newcommand{\Rs}{\mathbb{R}^{**}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\PX}{\mathcal{P}(X)}
\newcommand*\rot{\rotatebox{90}}
\newcommand*\OK{\ding{51}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Answer}{\vspace{2mm}\textbf{\underline{Answer}}\\}
\newcolumntype{L}{>{$}l<{$}}
\newcolumntype{C}{>{$}c<{$}}
\newcommand{\GL}{\text{GL}}
\newcommand{\SL}{\text{SL}}
\newcommand{\floor}[1]{\lfloor #1 \rfloor}
\newcommand\var[1]{\mathrm{Var}\left[{#1}\right]}
\newcommand\myvar{\mathrm{Var}}
\newcommand\Var{\myvar}
\newcommand\cov{\mathrm{Cov}}
\newcommand\Cov{\mathrm{Cov}}


\newcommand{\stirling}[2]{\genfrac{\{}{\}}{0pt}{}{#1}{#2}}

\pagestyle{fancy}
\fancyhf{}
\renewcommand{\sectionmark}[1]{\markright{\thesection.\ #1}}
\lhead{\fancyplain{}{}} 
\fancyhead[RE,RO]{Math 4450, Fall 2025}
\fancyfoot[RE,RO]{\thepage}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}
\begin{flushright}
\begin{minipage}{.33\textwidth}
\rightline{YOUR NAME}
\rightline{\href{mailto:YOUR EMAIL}{YOUR EMAIL}}
\rightline{\today}
\end{minipage}
\end{flushright}

\begin{center}
{\large{\textbf{Homework 8}}}
\end{center}

\begin{enumerate}
  
  \item (1 point) Suppose a turtle lays a random number of eggs $Y$, and the probability that a hatchling from any given egg survives is $p$. If $Y$ is modeled using a Poisson$(\lambda)$ distribution, and the $i$th egg survives following an independent model $X_i \sim \text{Bernoulli}(p)$ what is the expected value and variance of $X$, the total number of hatchlings that survive?

  \item (1 point) Show that $E\big[\Var(Y | X)\big] \leq \Var(Y)$.
  
  \item (1 point) Let $T \sim \text{Exp}(\lambda)$, and let $U$ be uniform on the interval $[0, T]$ (that is, we have a hierarchical model where $U$ depends on $T$). Find $E[U]$ and $\Var(U)$.   

  \item Use the definition of Covariance to show the following:
  \begin{enumerate}
    \item (0.5 points) $\Cov(aX, bY) = ab\,\Cov(X, Y)$ \label{prob:cov1}.
    \item (0.5 poitns) $\Cov(X, Y + Z) = \Cov(X, Y) + \Cov(X, Z)$ \label{prob:cov2}.
    \item (1 point) Now combine the results from parts \ref{prob:cov1} and \ref{prob:cov2} to show the following: 
    $$
    \Cov(aW + bX, cY + dZ) = ac\,\Cov(W, Y) + bc\,\Cov(X, Y) + ad\,\Cov(W, Z) + bd\,\Cov(X, Z).
    $$
  \end{enumerate}
  
  \item (1 point) Consider a symmetric random walk, starting at the position $S_0 = 0$. At time $n$, we write the position $S_n$ as 
  $$
  S_n = S_{n - 1} + X_n,
  $$
  where the $X_n$ are mean zero, independent steps with variance $\sigma^2$. For any $n, m > 0$, find an expression for $\Cov(S_n, S_m)$.
  
  \item (3 points) In time series analysis, we are interested in the behaviour of a sequence of random variables $X_1, X_2, \ldots$, where the order of the random variables is an important feature of their behavior.
  An important concept in time series is  \emph{stationarity}. A times series is said to be (\emph{weakly}) \emph{stationary} if $\Var(X_n) < \infty$ for all $n$, and
  \begin{itemize}
    \item $E[X_n] = \mu < \infty$, for all $n \in \{1, 2, \ldots\}$ (the mean doesn't depend on time).
    \item $\Cov(X_i, X_j) = \gamma_{|i - j|}$, or that the covariance only depends on the distance between $i$ and $j$. In other words, for all time points $n$ and values $h \in \{0, 1, 2, \ldots\}$, there exists some $\gamma_h$ such that
    \begin{equation}
    \Cov(X_n, X_{n + h}) = \Cov(X_{n + h}, X_n) = \gamma_h. \label{eq:cov}
    \end{equation}
  \end{itemize}
  For this problem, we will assume that $X_n$ comes from an Auto-regressive (1) model.
  That is, for some $-1 < \phi < 1$, we assume that
  \begin{equation}
  X_n = \phi X_{n-1} + \epsilon_n, \label{eq:ar1}
  \end{equation}
  where $\epsilon_n$ are iid $N(0, \sigma^2)$ random variables.
  We will now assume that $X_0$ is sampled from the \emph{stationary distribution}, or that $E[X_0] = 0$, and $\Var(X_0) = \gamma_0$.
  \textbf{Your task is to use the information above to find an expression for} $\gamma_h$ \textbf{ in terms of } $h, \sigma^2$ and $\phi$. The steps below will should help you through this process.
  \begin{enumerate}
    \item (1 point) Step (1): Use properties of the covariance, Equations~\ref{eq:cov} and \ref{eq:ar1} to express $\gamma_h$ in terms of $\gamma_{h - 1}$:
    \begin{align*}
    \gamma_h &= \Cov(X_n, X_{n + h}) \quad \text{(By Eq.~\ref{eq:cov})}\\
      &= \Cov(X_n, \phi X_{n+h - 1} + \epsilon_{n + h}) \quad \text{(By Eq.~\ref{eq:ar1})} \\
      &= \ldots \text{ You continue from here }\ldots
    \end{align*}
    \item (1 point) Step (2): Using your result in the previous step, get an expression for $\gamma_h$ in terms of $\gamma_0$.
    \item (1 point) Step (3): Now our goal is to get an expression for $\gamma_0$, which is $\Cov(X_n, X_n)$ for all $n$:
    \begin{align*}
      \gamma_0 &= \Cov(X_n, X_n) \\
      &= \Cov(\phi X_{n-1} + \epsilon_{n-1}, \phi X_{n-1} + \epsilon_{n-1}) \quad \text{(By Eq.~\ref{eq:ar1})} \\
      &= \ldots \text{ You continue from here }\ldots
    \end{align*}
    \item (0 points, trivial) Step (4): Combine your results from Step 2 and Step 3 to get an expression of $\gamma_h$ in terms of $h, \sigma^2$ and $\phi$.
    \item (BONUS, +0.5): How does your result change if $X_0$ is not from the stationary distribution? Is the process weakly stationary? For instance, suppose $X_0 = x_0$, so that $X_0$ is not random but some constant.
  \end{enumerate}

\end{enumerate}

\end{document}
